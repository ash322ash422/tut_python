{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68394e10-5494-4717-973f-b338bbae0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping -1\n",
    "- Prerequisite: Little knowledge of HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980d6e16-adcc-4530-b331-09a7236a7e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (4.14.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (from requests) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (from requests) (2026.1.4)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (from beautifulsoup4) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hi\\desktop\\projects\\python_projects\\tutorial\\tut_tensorflow\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0950178-51c5-47e1-b7e7-41c48d8e3675",
   "metadata": {},
   "source": [
    "We’ll scrape example data from Books to Scrape (a legal practice website made for learning scraping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11422d9c-3aeb-4101-ac70-5fc069f4a286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecd37cd9-97a7-460e-b21e-06cfe751988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Website URL\n",
    "url = \"http://books.toscrape.com/catalogue/page-1.html\"\n",
    "\n",
    "# Send request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse HTML\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all book containers\n",
    "items = soup.find_all(\"article\", class_=\"product_pod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aae9c538-ca30-4aab-a852-4563ce9efbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<article class=\"product_pod\">\n",
       " <div class=\"image_container\">\n",
       " <a href=\"a-light-in-the-attic_1000/index.html\"><img alt=\"A Light in the Attic\" class=\"thumbnail\" src=\"../media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg\"/></a>\n",
       " </div>\n",
       " <p class=\"star-rating Three\">\n",
       " <i class=\"icon-star\"></i>\n",
       " <i class=\"icon-star\"></i>\n",
       " <i class=\"icon-star\"></i>\n",
       " <i class=\"icon-star\"></i>\n",
       " <i class=\"icon-star\"></i>\n",
       " </p>\n",
       " <h3><a href=\"a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a></h3>\n",
       " <div class=\"product_price\">\n",
       " <p class=\"price_color\">Â£51.77</p>\n",
       " <p class=\"instock availability\">\n",
       " <i class=\"icon-ok\"></i>\n",
       "     \n",
       "         In stock\n",
       "     \n",
       " </p>\n",
       " <form>\n",
       " <button class=\"btn btn-primary btn-block\" data-loading-text=\"Adding...\" type=\"submit\">Add to basket</button>\n",
       " </form>\n",
       " </div>\n",
       " </article>,\n",
       " <article class=\"product_pod\">\n",
       " <div class=\"image_container\">\n",
       " <a href=\"tipping-the-velvet_999/index.html\"><img alt=\"Tipping the Velvet\" class=\"thumbnail\" src=\"../media/cache/26/0c/260c6ae16bce31c8f8c95daddd9f4a1c.jpg\"/></a>\n",
       " </div>\n",
       " <p class=\"star-rating One\">\n",
       " <i class=\"icon-star\"></i>\n",
       " <i class=\"icon-star\"></i>\n",
       " <i class=\"icon-star\"></i>\n",
       " <i class=\"icon-star\"></i>\n",
       " <i class=\"icon-star\"></i>\n",
       " </p>\n",
       " <h3><a href=\"tipping-the-velvet_999/index.html\" title=\"Tipping the Velvet\">Tipping the Velvet</a></h3>\n",
       " <div class=\"product_price\">\n",
       " <p class=\"price_color\">Â£53.74</p>\n",
       " <p class=\"instock availability\">\n",
       " <i class=\"icon-ok\"></i>\n",
       "     \n",
       "         In stock\n",
       "     \n",
       " </p>\n",
       " <form>\n",
       " <button class=\"btn btn-primary btn-block\" data-loading-text=\"Adding...\" type=\"submit\">Add to basket</button>\n",
       " </form>\n",
       " </div>\n",
       " </article>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5407b968-0d66-4303-a6be-3b5fcdaa7e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ad4e1b4-c97f-43b9-a7d2-81155b674efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we define a function that performs web scraping:\n",
    "\n",
    "def scrape_books():\n",
    "    url = \"http://books.toscrape.com/catalogue/page-1.html\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find all book containers\n",
    "    items = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "\n",
    "    # Store data\n",
    "    books = []\n",
    "    \n",
    "    for item in items:\n",
    "        title = item.h3.a[\"title\"]\n",
    "        price = item.find(\"p\", class_=\"price_color\").text\n",
    "        availability = item.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "    \n",
    "        books.append({\n",
    "            \"Title\": title,\n",
    "            \"Price\": price,\n",
    "            \"Availability\": availability\n",
    "        })\n",
    "        \n",
    "\n",
    "    # Save correctly\n",
    "    with open(\"books_data.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        fieldnames = [\"Title\", \"Price\", \"Availability\"]\n",
    "\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(books)\n",
    "\n",
    "    print(\"Data saved successfully!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "729d9386-06e2-4c09-a1ba-cfcbce649911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Title': 'A Light in the Attic', 'Price': 'Â£51.77', 'Availability': 'In stock'}, {'Title': 'Tipping the Velvet', 'Price': 'Â£53.74', 'Availability': 'In stock'}, {'Title': 'Soumission', 'Price': 'Â£50.10', 'Availability': 'In stock'}, {'Title': 'Sharp Objects', 'Price': 'Â£47.82', 'Availability': 'In stock'}, {'Title': 'Sapiens: A Brief History of Humankind', 'Price': 'Â£54.23', 'Availability': 'In stock'}, {'Title': 'The Requiem Red', 'Price': 'Â£22.65', 'Availability': 'In stock'}, {'Title': 'The Dirty Little Secrets of Getting Your Dream Job', 'Price': 'Â£33.34', 'Availability': 'In stock'}, {'Title': 'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull', 'Price': 'Â£17.93', 'Availability': 'In stock'}, {'Title': 'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics', 'Price': 'Â£22.60', 'Availability': 'In stock'}, {'Title': 'The Black Maria', 'Price': 'Â£52.15', 'Availability': 'In stock'}, {'Title': 'Starving Hearts (Triangular Trade Trilogy, #1)', 'Price': 'Â£13.99', 'Availability': 'In stock'}, {'Title': \"Shakespeare's Sonnets\", 'Price': 'Â£20.66', 'Availability': 'In stock'}, {'Title': 'Set Me Free', 'Price': 'Â£17.46', 'Availability': 'In stock'}, {'Title': \"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\", 'Price': 'Â£52.29', 'Availability': 'In stock'}, {'Title': 'Rip it Up and Start Again', 'Price': 'Â£35.02', 'Availability': 'In stock'}, {'Title': 'Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991', 'Price': 'Â£57.25', 'Availability': 'In stock'}, {'Title': 'Olio', 'Price': 'Â£23.88', 'Availability': 'In stock'}, {'Title': 'Mesaerion: The Best Science Fiction Stories 1800-1849', 'Price': 'Â£37.59', 'Availability': 'In stock'}, {'Title': 'Libertarianism for Beginners', 'Price': 'Â£51.33', 'Availability': 'In stock'}, {'Title': \"It's Only the Himalayas\", 'Price': 'Â£45.17', 'Availability': 'In stock'}]\n",
      "Data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "scrape_books()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bead6-e720-46d7-8a80-7bf06ca423b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e7272-5c0a-4a92-8514-c7629decad43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68e05e5d-da7e-4861-9783-4abcc05caaa6",
   "metadata": {},
   "source": [
    "## Make It Automated (Daily Run)\n",
    "Python collects data every day automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8474342f-ce9e-4885-82e7-9bd5626ef491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "\n",
    "def job():\n",
    "    print(\"Running scraper...\")\n",
    "    # call your scraping function here\n",
    "    scrape_books()\n",
    "\n",
    "schedule.every().day.at(\"09:00\").do(job)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa5b48-22c5-4802-85a2-263177fa2649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91870f16-1101-481e-b335-9654ebbbcf0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc72e7e-4697-44a6-8ef4-0c9b8752f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Python File: Industry standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9986c69-11a6-4770-8f7f-ab08b2f3440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "# -----------------------------\n",
    "# Web Scraping Function\n",
    "# -----------------------------\n",
    "def scrape_books():\n",
    "    url = \"http://books.toscrape.com/catalogue/page-1.html\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find all book containers\n",
    "    items = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "\n",
    "    # Store data\n",
    "    books = []\n",
    "    \n",
    "    for item in items:\n",
    "        title = item.h3.a[\"title\"]\n",
    "        price = item.find(\"p\", class_=\"price_color\").text\n",
    "        availability = item.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "    \n",
    "        books.append({\n",
    "            \"Title\": title,\n",
    "            \"Price\": price,\n",
    "            \"Availability\": availability\n",
    "        })\n",
    "        \n",
    "\n",
    "    # Save correctly\n",
    "    with open(\"books_data.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        fieldnames = [\"Title\", \"Price\", \"Availability\"]\n",
    "\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(books)\n",
    "\n",
    "    print(\"Data saved successfully!\")\n",
    "        \n",
    "\n",
    "# -----------------------------\n",
    "# Scheduled Job\n",
    "# -----------------------------\n",
    "def job():\n",
    "    print(\"Running scraper...\")\n",
    "    scrape_books()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main Function\n",
    "# -----------------------------\n",
    "def main():\n",
    "    # Schedule task\n",
    "    schedule.every().day.at(\"09:00\").do(job)\n",
    "\n",
    "    print(\"Scheduler started... Waiting for next run.\")\n",
    "\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(60)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Entry Point (BEST PRACTICE)\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
